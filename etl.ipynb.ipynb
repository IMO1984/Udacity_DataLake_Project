{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "import configparser\n",
    "from datetime import datetime\n",
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf, col, lower, monotonically_increasing_id\n",
    "from pyspark.sql.functions import year, month, dayofmonth, hour, weekofyear, date_format\n",
    "\n",
    "from pyspark.sql.types import StructType as R, StructField as Fld, \\\n",
    "     DoubleType as Dbl, LongType as Long, StringType as Str, \\\n",
    "     IntegerType as Int, DecimalType as Dec, DateType as Date, \\\n",
    "     TimestampType as Stamp\n",
    "\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config.read('dl.cfg')\n",
    "\n",
    "os.environ['AWS_ACCESS_KEY_ID']=config['AWS']['AWS_ACCESS_KEY_ID']\n",
    "os.environ['AWS_SECRET_ACCESS_KEY']=config['AWS']['AWS_SECRET_ACCESS_KEY']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .config(\"spark.jars.packages\", \"org.apache.hadoop:hadoop-aws:2.7.0\") \\\n",
    "    .getOrCreate()\n",
    "spark.conf.set(\"mapreduce.fileoutputcommitter.algorithm.version\", \"2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "song_data = \"song-data/song_data/*/*/*/\"\n",
    "#song-data/song_data/A/A/A/TRAAAAW128F429D538.json\n",
    "\n",
    "song_schema = R([\n",
    "    Fld(\"num_songs\", Int()),\n",
    "    Fld(\"artist_id\", Str()),\n",
    "    Fld(\"artist_latitude\", Dec()),\n",
    "    Fld(\"artist_longitude\", Dec()),\n",
    "    Fld(\"artist_location\", Str()),\n",
    "    Fld(\"artist_name\", Str()),\n",
    "    Fld(\"song_id\", Str()),\n",
    "    Fld(\"title\", Str()),\n",
    "    Fld(\"duration\", Dbl()),\n",
    "    Fld(\"year\", Long())\n",
    "])\n",
    "song_df = spark.read.json(song_data,schema=song_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- num_songs: integer (nullable = true)\n",
      " |-- artist_id: string (nullable = true)\n",
      " |-- artist_latitude: decimal(10,0) (nullable = true)\n",
      " |-- artist_longitude: decimal(10,0) (nullable = true)\n",
      " |-- artist_location: string (nullable = true)\n",
      " |-- artist_name: string (nullable = true)\n",
      " |-- song_id: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- duration: double (nullable = true)\n",
      " |-- year: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "song_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------------+---------------+----------------+-----------------+----------------------------------------------------------------------------------------------+------------------+----------------------------------------------------+---------+----+\n",
      "|num_songs|artist_id         |artist_latitude|artist_longitude|artist_location  |artist_name                                                                                   |song_id           |title                                               |duration |year|\n",
      "+---------+------------------+---------------+----------------+-----------------+----------------------------------------------------------------------------------------------+------------------+----------------------------------------------------+---------+----+\n",
      "|1        |ARDR4AC1187FB371A1|null           |null            |                 |Montserrat Caballé;Placido Domingo;Vicente Sardinero;Judith Blegen;Sherrill Milnes;Georg Solti|SOBAYLL12A8C138AF9|Sono andati? Fingevo di dormire                     |511.16363|0   |\n",
      "|1        |AREBBGV1187FB523D2|null           |null            |Houston, TX      |Mike Jones (Featuring CJ_ Mello & Lil' Bran)                                                  |SOOLYAZ12A6701F4A6|Laws Patrolling (Album Version)                     |173.66159|0   |\n",
      "|1        |ARMAC4T1187FB3FA4C|41             |-74             |Morris Plains, NJ|The Dillinger Escape Plan                                                                     |SOBBUGU12A8C13E95D|Setting Fire to Sleeping Giants                     |207.77751|2004|\n",
      "|1        |ARPBNLO1187FB3D52F|41             |-74             |New York, NY     |Tiny Tim                                                                                      |SOAOIBZ12AB01815BE|I Hold Your Hand In Mine [Live At Royal Albert Hall]|43.36281 |2000|\n",
      "|1        |ARDNS031187B9924F0|33             |-83             |Georgia          |Tim Wilson                                                                                    |SONYPOM12A8C13B2D7|I Think My Wife Is Running Around On Me (Taco Hell) |186.48771|2005|\n",
      "+---------+------------------+---------------+----------------+-----------------+----------------------------------------------------------------------------------------------+------------------+----------------------------------------------------+---------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "song_df.show(5, truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "columns = ['title','artist_name']\n",
    "\n",
    "for colName in columns:\n",
    "    song_df = song_df.withColumn(colName, lower(col(colName)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# extract columns to create songs table\n",
    "songs_table = song_df.select(\"song_id\",\n",
    "                        \"title\",\n",
    "                        \"artist_id\",\n",
    "                        \"year\",\n",
    "                        \"duration\").dropDuplicates([\"song_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+----------------------------------------------------+------------------+----+---------+\n",
      "|song_id           |title                                               |artist_id         |year|duration |\n",
      "+------------------+----------------------------------------------------+------------------+----+---------+\n",
      "|SOBAYLL12A8C138AF9|sono andati? fingevo di dormire                     |ARDR4AC1187FB371A1|0   |511.16363|\n",
      "|SOOLYAZ12A6701F4A6|laws patrolling (album version)                     |AREBBGV1187FB523D2|0   |173.66159|\n",
      "|SOBBUGU12A8C13E95D|setting fire to sleeping giants                     |ARMAC4T1187FB3FA4C|2004|207.77751|\n",
      "|SOAOIBZ12AB01815BE|i hold your hand in mine [live at royal albert hall]|ARPBNLO1187FB3D52F|2000|43.36281 |\n",
      "|SONYPOM12A8C13B2D7|i think my wife is running around on me (taco hell) |ARDNS031187B9924F0|2005|186.48771|\n",
      "+------------------+----------------------------------------------------+------------------+----+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "song_df.select(\"song_id\",\n",
    "                        \"title\",\n",
    "                        \"artist_id\",\n",
    "                        \"year\",\n",
    "                        \"duration\").show(5,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+--------------------------+------------------+----+---------+\n",
      "|song_id           |title                     |artist_id         |year|duration |\n",
      "+------------------+--------------------------+------------------+----+---------+\n",
      "|SOGOSOV12AF72A285E|¿dónde va chichi?         |ARGUVEV1187B98BA17|1997|313.12934|\n",
      "|SOMZWCG12A8C13C480|i didn't mean to          |ARD7TVE1187B99BFB1|0   |218.93179|\n",
      "|SOUPIRU12A6D4FA1E1|der kleine dompfaff       |ARJIE2Y1187B994AB7|0   |152.92036|\n",
      "|SOXVLOJ12AB0189215|amor de cabaret           |ARKRRTF1187B9984DA|0   |177.47546|\n",
      "|SOWTBJW12AC468AC6E|broken-down merry-go-round|ARQGYP71187FB44566|0   |151.84934|\n",
      "+------------------+--------------------------+------------------+----+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "songs_table.show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# write songs table to parquet files partitioned by year and artist\n",
    "songs_table.write.parquet(\"output_data/\" + \"songs_table.parquet\",\n",
    "                          partitionBy = [\"year\", \"artist_id\"],\n",
    "                          mode = \"overwrite\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# extract columns to create artists table\n",
    "artists_table = song_df.select(\"artist_id\",\n",
    "                          \"artist_name\",\n",
    "                          \"artist_location\",\n",
    "                          \"artist_latitude\",\n",
    "                          \"artist_longitude\").dropDuplicates([\"artist_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# write artists table to parquet files\n",
    "artists_table.write.parquet(\"output_data/\" + \"artists_table.parquet\", mode = \"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "log_data = \"log-data/\"\n",
    "#log-data/2018-11-01-events.json\n",
    "\n",
    "log_schema = R([\n",
    "    Fld(\"artist\", Str()),\n",
    "    Fld(\"auth\", Str()),\n",
    "    Fld(\"firstName\", Str()),\n",
    "    Fld(\"gender\", Str()),\n",
    "    Fld(\"itemInSession\", Long()),\n",
    "    Fld(\"lastName\", Str()),\n",
    "    Fld(\"length\", Dbl()),\n",
    "    Fld(\"level\", Str()),\n",
    "    Fld(\"location\", Str()),\n",
    "    Fld(\"method\", Str()),\n",
    "    Fld(\"page\", Str()),\n",
    "    Fld(\"registration\", Dbl()),\n",
    "    Fld(\"sessionId\", Str()),\n",
    "    Fld(\"song\", Str()),\n",
    "    Fld(\"status\", Str()),\n",
    "    Fld(\"ts\", Long()),\n",
    "    Fld(\"userAgent\", Str()),\n",
    "    Fld(\"userId\", Str())\n",
    "])\n",
    "\n",
    "log_df = spark.read.json(log_data, schema=log_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- artist: string (nullable = true)\n",
      " |-- auth: string (nullable = true)\n",
      " |-- firstName: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- itemInSession: long (nullable = true)\n",
      " |-- lastName: string (nullable = true)\n",
      " |-- length: double (nullable = true)\n",
      " |-- level: string (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- method: string (nullable = true)\n",
      " |-- page: string (nullable = true)\n",
      " |-- registration: double (nullable = true)\n",
      " |-- sessionId: string (nullable = true)\n",
      " |-- song: string (nullable = true)\n",
      " |-- status: string (nullable = true)\n",
      " |-- ts: long (nullable = true)\n",
      " |-- userAgent: string (nullable = true)\n",
      " |-- userId: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# filter by actions for song plays\n",
    "log_df = log_df.filter(log_df.page == \"NextSong\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "columns = ['song','artist']\n",
    "\n",
    "for colName in columns:\n",
    "    log_df = log_df.withColumn(colName, lower(col(colName)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------------------------------------------+\n",
      "|userId|song                                          |\n",
      "+------+----------------------------------------------+\n",
      "|26    |sehr kosmisch                                 |\n",
      "|26    |the big gundown                               |\n",
      "|26    |marry me                                      |\n",
      "|61    |blackbird                                     |\n",
      "|80    |best of both worlds (remastered album version)|\n",
      "+------+----------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_df.select('userId','song').show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------------------------------------------+\n",
      "|userId|song                                          |\n",
      "+------+----------------------------------------------+\n",
      "|26    |sehr kosmisch                                 |\n",
      "|26    |the big gundown                               |\n",
      "|26    |marry me                                      |\n",
      "|61    |blackbird                                     |\n",
      "|80    |best of both worlds (remastered album version)|\n",
      "+------+----------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_df.select('userId','song').show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "log_df = log_df.withColumn('timestamp',( (log_df.ts.cast('float')/1000).cast(\"timestamp\")) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----------------------+\n",
      "|ts           |timestamp              |\n",
      "+-------------+-----------------------+\n",
      "|1542241826796|2018-11-15 00:29:39.712|\n",
      "|1542242481796|2018-11-15 00:40:35.072|\n",
      "|1542242741796|2018-11-15 00:44:57.216|\n",
      "|1542253449796|2018-11-15 03:44:05.12 |\n",
      "|1542260935796|2018-11-15 05:48:36.224|\n",
      "+-------------+-----------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_df.select('ts','timestamp').show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+---------+------+-----+\n",
      "|user_id|first_name|last_name|gender|level|\n",
      "+-------+----------+---------+------+-----+\n",
      "|51     |Maia      |Burke    |F     |free |\n",
      "|7      |Adelyn    |Jordan   |F     |free |\n",
      "|15     |Lily      |Koch     |F     |paid |\n",
      "|54     |Kaleb     |Cook     |M     |free |\n",
      "|101    |Jayden    |Fox      |M     |free |\n",
      "+-------+----------+---------+------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# extract columns for users table    \n",
    "users_table = log_df.selectExpr(\"userId as user_id\",\n",
    "                            \"firstName as first_name\",\n",
    "                            \"lastName as last_name\",\n",
    "                            \"gender\",\n",
    "                            \"level\").dropDuplicates([\"user_id\"]) \n",
    "users_table.show(5, truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# write users table to parquet files\n",
    "users_table.write.parquet(\"output_data/\" + \"users_table.parquet\",mode = \"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+----+---+----+-----+----+-------+\n",
      "|start_time             |hour|day|week|month|year|weekday|\n",
      "+-----------------------+----+---+----+-----+----+-------+\n",
      "|2018-11-28 06:22:49.344|6   |28 |48  |11   |2018|4      |\n",
      "|2018-11-28 12:14:31.936|12  |28 |48  |11   |2018|4      |\n",
      "|2018-11-28 17:07:15.584|17  |28 |48  |11   |2018|4      |\n",
      "|2018-11-28 20:41:20.64 |20  |28 |48  |11   |2018|4      |\n",
      "|2018-11-05 18:13:05.152|18  |5  |45  |11   |2018|2      |\n",
      "+-----------------------+----+---+----+-----+----+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# extract columns to create time table\n",
    "time_table = log_df.selectExpr(\"timestamp as start_time\",\n",
    "                           \"hour(timestamp) as hour\",\n",
    "                           \"dayofmonth(timestamp) as day\",\n",
    "                           \"weekofyear(timestamp) as week\",\n",
    "                           \"month(timestamp) as month\",\n",
    "                           \"year(timestamp) as year\",\n",
    "                           \"dayofweek(timestamp) as weekday\"\n",
    "                           ).dropDuplicates([\"start_time\"])\n",
    "\n",
    "time_table.show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# write time table to parquet files partitioned by year and month\n",
    "time_table.write.parquet(\"output_data/\"  + \"time_table.parquet\",\n",
    "                         partitionBy = [\"year\", \"month\", \"week\"],\n",
    "                         mode = \"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "song_log_joined_df = log_df.join(song_df, (log_df.song == song_df.title) & (log_df.artist == song_df.artist_name) & (log_df.length == song_df.duration), how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6820"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "song_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "song_log_joined_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+------------------+------------------+-----+----------+--------------------+--------------------+----+-----+----+-------------+\n",
      "|user_id|          start_time|           song_id|         artist_id|level|session_id|            location|          user_agent|year|month|week|  songplay_id|\n",
      "+-------+--------------------+------------------+------------------+-----+----------+--------------------+--------------------+----+-----+----+-------------+\n",
      "|     15|2018-11-21 21:56:...|SOZCTXZ12AB0182364|AR5KOSW1187FB35FF4| paid|       818|Chicago-Napervill...|\"Mozilla/5.0 (X11...|2018|   11|  47|1649267441664|\n",
      "+-------+--------------------+------------------+------------------+-----+----------+--------------------+--------------------+----+-----+----+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import monotonically_increasing_id\n",
    "songplays_table = song_log_joined_df.distinct() \\\n",
    "                    .selectExpr(\"userId as user_id\", \"timestamp\", \"song_id\", \"artist_id\", \"level\", \"sessionId\", \"location\", \"userAgent\", \\\n",
    "                                \"year(timestamp) as year\",\"month(timestamp) as month\",\"weekofyear(timestamp) as week\") \\\n",
    "                    .withColumn(\"songplay_id\", monotonically_increasing_id()) \\\n",
    "                    .withColumnRenamed(\"userId\",\"user_id\")        \\\n",
    "                    .withColumnRenamed(\"timestamp\",\"start_time\")  \\\n",
    "                    .withColumnRenamed(\"sessionId\",\"session_id\")  \\\n",
    "                    .withColumnRenamed(\"userAgent\", \"user_agent\")         \n",
    "\n",
    "songplays_table.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "songplays_table.write.parquet(\"output_data/\" + \"songplays_table.parquet\",\n",
    "                              partitionBy=[\"year\", \"month\",\"week\"],\n",
    "                              mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
